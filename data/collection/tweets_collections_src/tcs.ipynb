{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f375fd8b-5a6f-4d14-bebe-5e31f483100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30bd6d97-019d-4121-bc36-9c06db3cdd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to cookies2.json.\n",
      "Total tweets collected so far: 10\n",
      "Total tweets collected so far: 20\n",
      "Total tweets collected so far: 30\n",
      "Total tweets collected so far: 40\n",
      "Total tweets collected so far: 50\n",
      "Total tweets collected so far: 60\n",
      "Finished collecting tweets. Total tweets collected: 60\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "from requests.exceptions import ReadTimeout  # Import ReadTimeout exception\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MINIMUM_TWEETS = 10\n",
    "START_DATE = datetime(2022, 1, 1)  # Start date of the range\n",
    "END_DATE = datetime(2023, 12, 31)  # End date of the range\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Delay between requests in seconds\n",
    "CSV_FILE = 'TCS.csv'  # Updated file for TCS data\n",
    "SUMMARY_FILE = 'TCS_Collection_Summary.csv'  # Updated summary file for TCS\n",
    "\n",
    "# Initialize Twitter client\n",
    "client = Client()  # Initialize your Twitter client\n",
    "client.load_cookies('cookies.json')\n",
    "cookies_file = 'cookies.json'\n",
    "cookies2_file = 'cookies2.json'\n",
    "current_cookies = cookies_file\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='tcs_tweet_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize counters\n",
    "total_tweets_collected = 0\n",
    "daily_stats = []\n",
    "\n",
    "def switch_cookies():\n",
    "    \"\"\"Switches between cookies.json and cookies2.json.\"\"\"\n",
    "    global current_cookies\n",
    "    if current_cookies == cookies_file:\n",
    "        client.load_cookies(cookies2_file)\n",
    "        current_cookies = cookies2_file\n",
    "    else:\n",
    "        client.load_cookies(cookies_file)\n",
    "        current_cookies = cookies_file\n",
    "    print(f'Switched to {current_cookies}.')  # Added print statement\n",
    "    logging.info(f'Switched to {current_cookies}.')\n",
    "\n",
    "def get_tweets(query, tweets):\n",
    "    if tweets is None:\n",
    "        logging.info(f'Getting tweets for query: {query}...')\n",
    "        tweets = client.search_tweet(query, product='Top')\n",
    "    else:\n",
    "        wait_time = randint(5, 10)\n",
    "        logging.info(f'Getting next tweets after {wait_time} seconds ...')\n",
    "        time.sleep(wait_time)\n",
    "        tweets = tweets.next()\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def construct_query(date):\n",
    "    next_day = date + timedelta(days=1)\n",
    "    query = (f'(TCS OR \"Tata Consultancy Services\" OR #TCS OR #TataConsultancy OR '\n",
    "             f'Stock OR Market OR #StockMarket OR #MarketAnalysis) '\n",
    "             f'lang:en until:{next_day.strftime(\"%Y-%m-%d\")} since:{date.strftime(\"%Y-%m-%d\")}')\n",
    "    return query\n",
    "\n",
    "def delay_for_minutes(minutes=5):\n",
    "    \"\"\"Delays for the specified number of minutes, showing progress with tqdm.\"\"\"\n",
    "    wait_time = minutes * 60  # Convert minutes to seconds\n",
    "    with tqdm(total=wait_time, desc=f'Waiting for {minutes} minutes', unit='s', leave=True) as rate_pbar:\n",
    "        for _ in range(wait_time):\n",
    "            time.sleep(1)\n",
    "            rate_pbar.update(1)\n",
    "\n",
    "def collect_tweets_for_day(date):\n",
    "    global total_tweets_collected\n",
    "    query = construct_query(date)\n",
    "    tweet_count = 0\n",
    "    tweets = None\n",
    "    retries = 0\n",
    "    max_retries = 5  # Set a maximum number of retries\n",
    "    \n",
    "    while tweet_count < MINIMUM_TWEETS:\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "        except TooManyRequests as e:\n",
    "            rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "            current_time = datetime.now()\n",
    "            wait_time = (rate_limit_reset - current_time).total_seconds()\n",
    "            \n",
    "            # Switch cookies and retry\n",
    "            logging.warning(f'Rate limit reached. Switching cookies.')\n",
    "            switch_cookies()  # Added print and logging when switching cookies\n",
    "            \n",
    "            # Immediately retry with new cookies\n",
    "            try:\n",
    "                tweets = get_tweets(query, tweets)\n",
    "                logging.info('Successfully resumed after switching cookies.')\n",
    "            except TooManyRequests as e:\n",
    "                logging.warning(f'Rate limit still in place even after switching cookies.')\n",
    "                if wait_time > 0:\n",
    "                    logging.warning(f'Waiting until {rate_limit_reset}')\n",
    "                    delay_for_minutes(5)  # Now wait for 5 minutes instead of 15\n",
    "                else:\n",
    "                    logging.warning(f'Rate limit reset time is in the past. Waiting for 5 minutes as a precaution.')\n",
    "                    delay_for_minutes(5)  # Always wait for 5 minutes now\n",
    "            continue\n",
    "\n",
    "        # Catch ReadTimeout and retry\n",
    "        except ReadTimeout:\n",
    "            retries += 1\n",
    "            logging.error(f'ReadTimeout occurred. Retrying {retries}/{max_retries}...')\n",
    "            if retries > max_retries:\n",
    "                logging.error(f'Max retries reached for {date.strftime(\"%Y-%m-%d\")}. Moving on.')\n",
    "                break  # Exit the loop after max retries\n",
    "            else:\n",
    "                time.sleep(2 ** retries)  # Exponential backoff\n",
    "                continue  # Retry after waiting\n",
    "\n",
    "        if not tweets:\n",
    "            logging.info(f'No more tweets found for {date.strftime(\"%Y-%m-%d\")}')\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if tweet_count >= MINIMUM_TWEETS:\n",
    "                break\n",
    "            tweet_count += 1\n",
    "            total_tweets_collected += 1\n",
    "            tweet_data = [date.strftime('%Y-%m-%d'), tweet_count, tweet.user.name, tweet.text, tweet.created_at, tweet.retweet_count, tweet.favorite_count]\n",
    "            \n",
    "            with open(CSV_FILE, 'a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(tweet_data)\n",
    "\n",
    "        logging.info(f'Got {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}')\n",
    "        daily_stats.append([date.strftime('%Y-%m-%d'), tweet_count])\n",
    "    \n",
    "    if tweet_count < MINIMUM_TWEETS:\n",
    "        logging.warning(f'Collected {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}, which is less than the minimum of {MINIMUM_TWEETS}')\n",
    "    \n",
    "    logging.info(f'Done for {date.strftime(\"%Y-%m-%d\")}')\n",
    "    print(f'Total tweets collected so far: {total_tweets_collected}')\n",
    "\n",
    "def get_last_collected_date():\n",
    "    \"\"\"Reads the CSV file to find the last collected date.\"\"\"\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        return START_DATE\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        if len(rows) > 1:\n",
    "            last_date = rows[-1][0]\n",
    "            return datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    return START_DATE\n",
    "\n",
    "# Write header to the CSV file if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweet Count', 'Username', 'Text', 'Created At', 'Retweets', 'Likes'])\n",
    "\n",
    "# Get the starting date\n",
    "start_date = get_last_collected_date()\n",
    "if start_date > END_DATE:\n",
    "    print(f'All data has already been collected up to {END_DATE.strftime(\"%Y-%m-%d\")}.')\n",
    "else:\n",
    "    # Collect tweets for the specified date range\n",
    "    current_date = start_date\n",
    "    while current_date <= END_DATE:\n",
    "        collect_tweets_for_day(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    print(f'Finished collecting tweets. Total tweets collected: {total_tweets_collected}')\n",
    "\n",
    "    # Save summary to a CSV file\n",
    "    with open(SUMMARY_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweets Collected'])\n",
    "        writer.writerows(daily_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb326375-09be-4359-a717-4590f484ff5c",
   "metadata": {},
   "source": [
    "# HDFC Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25972d8f-d968-4c08-ac79-df7ec5dac861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 10\n",
      "Total tweets collected so far: 20\n",
      "Total tweets collected so far: 30\n",
      "Total tweets collected so far: 40\n",
      "Total tweets collected so far: 50\n",
      "Total tweets collected so far: 60\n",
      "Total tweets collected so far: 70\n",
      "Total tweets collected so far: 80\n",
      "Total tweets collected so far: 90\n",
      "Total tweets collected so far: 100\n",
      "Total tweets collected so far: 110\n",
      "Total tweets collected so far: 120\n",
      "Total tweets collected so far: 130\n",
      "Total tweets collected so far: 140\n",
      "Total tweets collected so far: 150\n",
      "Total tweets collected so far: 160\n",
      "Total tweets collected so far: 170\n",
      "Total tweets collected so far: 180\n",
      "Total tweets collected so far: 180\n",
      "Total tweets collected so far: 190\n",
      "Total tweets collected so far: 200\n",
      "Total tweets collected so far: 210\n",
      "Total tweets collected so far: 220\n",
      "Total tweets collected so far: 230\n",
      "Total tweets collected so far: 240\n",
      "Total tweets collected so far: 250\n",
      "Total tweets collected so far: 260\n",
      "Total tweets collected so far: 270\n",
      "Total tweets collected so far: 280\n",
      "Total tweets collected so far: 290\n",
      "Total tweets collected so far: 300\n",
      "Total tweets collected so far: 310\n",
      "Total tweets collected so far: 320\n",
      "Total tweets collected so far: 330\n",
      "Total tweets collected so far: 340\n",
      "Total tweets collected so far: 350\n",
      "Total tweets collected so far: 360\n",
      "Total tweets collected so far: 370\n",
      "Total tweets collected so far: 380\n",
      "Total tweets collected so far: 390\n",
      "Total tweets collected so far: 400\n",
      "Total tweets collected so far: 410\n",
      "Total tweets collected so far: 420\n",
      "Total tweets collected so far: 430\n",
      "Total tweets collected so far: 440\n",
      "Total tweets collected so far: 450\n",
      "Total tweets collected so far: 460\n",
      "Total tweets collected so far: 470\n",
      "Total tweets collected so far: 480\n",
      "Total tweets collected so far: 490\n",
      "Total tweets collected so far: 500\n",
      "Total tweets collected so far: 510\n",
      "Total tweets collected so far: 520\n",
      "Total tweets collected so far: 530\n",
      "Total tweets collected so far: 540\n",
      "Total tweets collected so far: 550\n",
      "Total tweets collected so far: 560\n",
      "Total tweets collected so far: 570\n",
      "Total tweets collected so far: 580\n",
      "Total tweets collected so far: 590\n",
      "Total tweets collected so far: 600\n",
      "Total tweets collected so far: 610\n",
      "Total tweets collected so far: 620\n",
      "Total tweets collected so far: 630\n",
      "Total tweets collected so far: 640\n",
      "Total tweets collected so far: 650\n",
      "Total tweets collected so far: 660\n",
      "Total tweets collected so far: 670\n",
      "Total tweets collected so far: 680\n",
      "Total tweets collected so far: 690\n",
      "Total tweets collected so far: 700\n",
      "Total tweets collected so far: 710\n",
      "Total tweets collected so far: 720\n",
      "Total tweets collected so far: 730\n",
      "Total tweets collected so far: 740\n",
      "Total tweets collected so far: 750\n",
      "Total tweets collected so far: 760\n",
      "Total tweets collected so far: 770\n",
      "Total tweets collected so far: 780\n",
      "Total tweets collected so far: 790\n",
      "Total tweets collected so far: 800\n",
      "Total tweets collected so far: 810\n",
      "Total tweets collected so far: 820\n",
      "Total tweets collected so far: 830\n",
      "Total tweets collected so far: 840\n",
      "Total tweets collected so far: 850\n",
      "Total tweets collected so far: 860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n",
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 870\n",
      "Total tweets collected so far: 880\n",
      "Total tweets collected so far: 890\n",
      "Total tweets collected so far: 900\n",
      "Total tweets collected so far: 910\n",
      "Total tweets collected so far: 920\n",
      "Total tweets collected so far: 930\n",
      "Total tweets collected so far: 940\n",
      "Total tweets collected so far: 950\n",
      "Total tweets collected so far: 960\n",
      "Total tweets collected so far: 970\n",
      "Total tweets collected so far: 980\n",
      "Total tweets collected so far: 980\n",
      "Total tweets collected so far: 990\n",
      "Total tweets collected so far: 1000\n",
      "Total tweets collected so far: 1010\n",
      "Total tweets collected so far: 1020\n",
      "Total tweets collected so far: 1030\n",
      "Total tweets collected so far: 1040\n",
      "Total tweets collected so far: 1050\n",
      "Total tweets collected so far: 1060\n",
      "Total tweets collected so far: 1070\n",
      "Total tweets collected so far: 1080\n",
      "Total tweets collected so far: 1090\n",
      "Total tweets collected so far: 1100\n",
      "Total tweets collected so far: 1110\n",
      "Total tweets collected so far: 1120\n",
      "Total tweets collected so far: 1130\n",
      "Total tweets collected so far: 1140\n",
      "Total tweets collected so far: 1150\n",
      "Total tweets collected so far: 1160\n",
      "Total tweets collected so far: 1170\n",
      "Total tweets collected so far: 1180\n",
      "Total tweets collected so far: 1190\n",
      "Total tweets collected so far: 1200\n",
      "Total tweets collected so far: 1210\n",
      "Total tweets collected so far: 1220\n",
      "Total tweets collected so far: 1230\n",
      "Total tweets collected so far: 1240\n",
      "Total tweets collected so far: 1250\n",
      "Total tweets collected so far: 1260\n",
      "Total tweets collected so far: 1270\n",
      "Total tweets collected so far: 1280\n",
      "Total tweets collected so far: 1290\n",
      "Total tweets collected so far: 1300\n",
      "Total tweets collected so far: 1310\n",
      "Total tweets collected so far: 1320\n",
      "Total tweets collected so far: 1330\n",
      "Total tweets collected so far: 1340\n",
      "Total tweets collected so far: 1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 1350\n",
      "Total tweets collected so far: 1360\n",
      "Total tweets collected so far: 1370\n",
      "Total tweets collected so far: 1380\n",
      "Total tweets collected so far: 1390\n",
      "Total tweets collected so far: 1400\n",
      "Total tweets collected so far: 1410\n",
      "Total tweets collected so far: 1420\n",
      "Total tweets collected so far: 1430\n",
      "Total tweets collected so far: 1440\n",
      "Total tweets collected so far: 1450\n",
      "Total tweets collected so far: 1460\n",
      "Total tweets collected so far: 1470\n",
      "Total tweets collected so far: 1480\n",
      "Total tweets collected so far: 1490\n",
      "Total tweets collected so far: 1500\n",
      "Total tweets collected so far: 1510\n",
      "Total tweets collected so far: 1520\n",
      "Total tweets collected so far: 1530\n",
      "Total tweets collected so far: 1540\n",
      "Total tweets collected so far: 1550\n",
      "Total tweets collected so far: 1560\n",
      "Total tweets collected so far: 1570\n",
      "Total tweets collected so far: 1580\n",
      "Total tweets collected so far: 1590\n",
      "Total tweets collected so far: 1600\n",
      "Total tweets collected so far: 1610\n",
      "Total tweets collected so far: 1620\n",
      "Total tweets collected so far: 1630\n",
      "Total tweets collected so far: 1640\n",
      "Total tweets collected so far: 1650\n",
      "Total tweets collected so far: 1660\n",
      "Total tweets collected so far: 1670\n",
      "Total tweets collected so far: 1680\n",
      "Total tweets collected so far: 1690\n",
      "Total tweets collected so far: 1700\n",
      "Total tweets collected so far: 1710\n",
      "Total tweets collected so far: 1720\n",
      "Total tweets collected so far: 1730\n",
      "Total tweets collected so far: 1740\n",
      "Total tweets collected so far: 1750\n",
      "Total tweets collected so far: 1760\n",
      "Total tweets collected so far: 1770\n",
      "Total tweets collected so far: 1780\n",
      "Total tweets collected so far: 1790\n",
      "Total tweets collected so far: 1800\n",
      "Total tweets collected so far: 1810\n",
      "Total tweets collected so far: 1820\n",
      "Total tweets collected so far: 1830\n",
      "Total tweets collected so far: 1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n",
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 1850\n",
      "Total tweets collected so far: 1860\n",
      "Total tweets collected so far: 1870\n",
      "Total tweets collected so far: 1880\n",
      "Total tweets collected so far: 1890\n",
      "Total tweets collected so far: 1900\n",
      "Total tweets collected so far: 1910\n",
      "Total tweets collected so far: 1920\n",
      "Total tweets collected so far: 1920\n",
      "Total tweets collected so far: 1930\n",
      "Total tweets collected so far: 1940\n",
      "Total tweets collected so far: 1950\n",
      "Total tweets collected so far: 1960\n",
      "Total tweets collected so far: 1970\n",
      "Total tweets collected so far: 1980\n",
      "Total tweets collected so far: 1990\n",
      "Total tweets collected so far: 2000\n",
      "Total tweets collected so far: 2010\n",
      "Total tweets collected so far: 2020\n",
      "Total tweets collected so far: 2030\n",
      "Total tweets collected so far: 2040\n",
      "Total tweets collected so far: 2050\n",
      "Total tweets collected so far: 2060\n",
      "Total tweets collected so far: 2070\n",
      "Total tweets collected so far: 2080\n",
      "Total tweets collected so far: 2090\n",
      "Total tweets collected so far: 2100\n",
      "Total tweets collected so far: 2100\n",
      "Total tweets collected so far: 2110\n",
      "Total tweets collected so far: 2120\n",
      "Total tweets collected so far: 2130\n",
      "Total tweets collected so far: 2140\n",
      "Total tweets collected so far: 2150\n",
      "Total tweets collected so far: 2160\n",
      "Total tweets collected so far: 2170\n",
      "Total tweets collected so far: 2180\n",
      "Total tweets collected so far: 2190\n",
      "Total tweets collected so far: 2200\n",
      "Total tweets collected so far: 2210\n",
      "Total tweets collected so far: 2220\n",
      "Total tweets collected so far: 2230\n",
      "Total tweets collected so far: 2240\n",
      "Total tweets collected so far: 2250\n",
      "Total tweets collected so far: 2260\n",
      "Total tweets collected so far: 2270\n",
      "Total tweets collected so far: 2280\n",
      "Total tweets collected so far: 2290\n",
      "Total tweets collected so far: 2300\n",
      "Total tweets collected so far: 2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 2320\n",
      "Total tweets collected so far: 2330\n",
      "Total tweets collected so far: 2340\n",
      "Total tweets collected so far: 2350\n",
      "Total tweets collected so far: 2360\n",
      "Total tweets collected so far: 2370\n",
      "Total tweets collected so far: 2380\n",
      "Total tweets collected so far: 2390\n",
      "Total tweets collected so far: 2400\n",
      "Total tweets collected so far: 2410\n",
      "Total tweets collected so far: 2420\n",
      "Total tweets collected so far: 2430\n",
      "Total tweets collected so far: 2440\n",
      "Total tweets collected so far: 2450\n",
      "Total tweets collected so far: 2460\n",
      "Total tweets collected so far: 2470\n",
      "Total tweets collected so far: 2480\n",
      "Total tweets collected so far: 2490\n",
      "Total tweets collected so far: 2500\n",
      "Total tweets collected so far: 2510\n",
      "Total tweets collected so far: 2520\n",
      "Total tweets collected so far: 2530\n",
      "Total tweets collected so far: 2540\n",
      "Total tweets collected so far: 2550\n",
      "Total tweets collected so far: 2560\n",
      "Total tweets collected so far: 2570\n",
      "Total tweets collected so far: 2580\n",
      "Total tweets collected so far: 2590\n",
      "Total tweets collected so far: 2600\n",
      "Total tweets collected so far: 2610\n",
      "Total tweets collected so far: 2620\n",
      "Total tweets collected so far: 2630\n",
      "Total tweets collected so far: 2640\n",
      "Total tweets collected so far: 2650\n",
      "Total tweets collected so far: 2660\n",
      "Total tweets collected so far: 2670\n",
      "Total tweets collected so far: 2680\n",
      "Total tweets collected so far: 2690\n",
      "Total tweets collected so far: 2700\n",
      "Total tweets collected so far: 2710\n",
      "Total tweets collected so far: 2720\n",
      "Total tweets collected so far: 2730\n",
      "Total tweets collected so far: 2740\n",
      "Total tweets collected so far: 2750\n",
      "Total tweets collected so far: 2760\n",
      "Total tweets collected so far: 2770\n",
      "Total tweets collected so far: 2780\n",
      "Total tweets collected so far: 2790\n",
      "Total tweets collected so far: 2800\n",
      "Total tweets collected so far: 2810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n",
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 2820\n",
      "Total tweets collected so far: 2830\n",
      "Total tweets collected so far: 2840\n",
      "Total tweets collected so far: 2850\n",
      "Total tweets collected so far: 2860\n",
      "Total tweets collected so far: 2870\n",
      "Total tweets collected so far: 2880\n",
      "Total tweets collected so far: 2890\n",
      "Total tweets collected so far: 2900\n",
      "Total tweets collected so far: 2910\n",
      "Total tweets collected so far: 2920\n",
      "Total tweets collected so far: 2930\n",
      "Total tweets collected so far: 2940\n",
      "Total tweets collected so far: 2950\n",
      "Total tweets collected so far: 2960\n",
      "Total tweets collected so far: 2970\n",
      "Total tweets collected so far: 2980\n",
      "Total tweets collected so far: 2990\n",
      "Total tweets collected so far: 3000\n",
      "Total tweets collected so far: 3010\n",
      "Total tweets collected so far: 3020\n",
      "Total tweets collected so far: 3030\n",
      "Total tweets collected so far: 3040\n",
      "Total tweets collected so far: 3050\n",
      "Total tweets collected so far: 3060\n",
      "Total tweets collected so far: 3070\n",
      "Total tweets collected so far: 3080\n",
      "Total tweets collected so far: 3090\n",
      "Total tweets collected so far: 3100\n",
      "Total tweets collected so far: 3110\n",
      "Total tweets collected so far: 3120\n",
      "Total tweets collected so far: 3130\n",
      "Total tweets collected so far: 3140\n",
      "Total tweets collected so far: 3150\n",
      "Total tweets collected so far: 3160\n",
      "Total tweets collected so far: 3170\n",
      "Total tweets collected so far: 3180\n",
      "Total tweets collected so far: 3190\n",
      "Total tweets collected so far: 3200\n",
      "Total tweets collected so far: 3210\n",
      "Total tweets collected so far: 3220\n",
      "Total tweets collected so far: 3230\n",
      "Total tweets collected so far: 3240\n",
      "Total tweets collected so far: 3250\n",
      "Total tweets collected so far: 3260\n",
      "Total tweets collected so far: 3270\n",
      "Total tweets collected so far: 3280\n",
      "Total tweets collected so far: 3290\n",
      "Total tweets collected so far: 3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 3310\n",
      "Total tweets collected so far: 3320\n",
      "Total tweets collected so far: 3330\n",
      "Total tweets collected so far: 3340\n",
      "Total tweets collected so far: 3350\n",
      "Total tweets collected so far: 3360\n",
      "Total tweets collected so far: 3370\n",
      "Total tweets collected so far: 3380\n",
      "Total tweets collected so far: 3390\n",
      "Total tweets collected so far: 3400\n",
      "Total tweets collected so far: 3410\n",
      "Total tweets collected so far: 3420\n",
      "Total tweets collected so far: 3430\n",
      "Total tweets collected so far: 3440\n",
      "Total tweets collected so far: 3450\n",
      "Total tweets collected so far: 3460\n",
      "Total tweets collected so far: 3470\n",
      "Total tweets collected so far: 3480\n",
      "Total tweets collected so far: 3490\n",
      "Total tweets collected so far: 3500\n",
      "Total tweets collected so far: 3510\n",
      "Total tweets collected so far: 3520\n",
      "Total tweets collected so far: 3520\n",
      "Total tweets collected so far: 3530\n",
      "Total tweets collected so far: 3540\n",
      "Total tweets collected so far: 3550\n",
      "Total tweets collected so far: 3560\n",
      "Total tweets collected so far: 3570\n",
      "Total tweets collected so far: 3580\n",
      "Total tweets collected so far: 3590\n",
      "Total tweets collected so far: 3600\n",
      "Total tweets collected so far: 3610\n",
      "Total tweets collected so far: 3620\n",
      "Total tweets collected so far: 3630\n",
      "Total tweets collected so far: 3640\n",
      "Total tweets collected so far: 3650\n",
      "Total tweets collected so far: 3660\n",
      "Total tweets collected so far: 3670\n",
      "Total tweets collected so far: 3680\n",
      "Total tweets collected so far: 3690\n",
      "Total tweets collected so far: 3700\n",
      "Total tweets collected so far: 3710\n",
      "Total tweets collected so far: 3720\n",
      "Total tweets collected so far: 3730\n",
      "Total tweets collected so far: 3740\n",
      "Total tweets collected so far: 3750\n",
      "Total tweets collected so far: 3760\n",
      "Total tweets collected so far: 3760\n",
      "Total tweets collected so far: 3770\n",
      "Total tweets collected so far: 3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n",
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 3790\n",
      "Total tweets collected so far: 3800\n",
      "Total tweets collected so far: 3810\n",
      "Total tweets collected so far: 3820\n",
      "Total tweets collected so far: 3830\n",
      "Total tweets collected so far: 3840\n",
      "Total tweets collected so far: 3850\n",
      "Total tweets collected so far: 3860\n",
      "Total tweets collected so far: 3870\n",
      "Total tweets collected so far: 3880\n",
      "Total tweets collected so far: 3890\n",
      "Total tweets collected so far: 3900\n",
      "Total tweets collected so far: 3910\n",
      "Total tweets collected so far: 3920\n",
      "Total tweets collected so far: 3930\n",
      "Total tweets collected so far: 3940\n",
      "Total tweets collected so far: 3950\n",
      "Total tweets collected so far: 3960\n",
      "Total tweets collected so far: 3970\n",
      "Total tweets collected so far: 3980\n",
      "Total tweets collected so far: 3990\n",
      "Total tweets collected so far: 4000\n",
      "Total tweets collected so far: 4010\n",
      "Total tweets collected so far: 4020\n",
      "Total tweets collected so far: 4030\n",
      "Total tweets collected so far: 4040\n",
      "Total tweets collected so far: 4050\n",
      "Total tweets collected so far: 4060\n",
      "Total tweets collected so far: 4070\n",
      "Total tweets collected so far: 4080\n",
      "Total tweets collected so far: 4090\n",
      "Total tweets collected so far: 4100\n",
      "Total tweets collected so far: 4110\n",
      "Total tweets collected so far: 4120\n",
      "Total tweets collected so far: 4130\n",
      "Total tweets collected so far: 4140\n",
      "Total tweets collected so far: 4150\n",
      "Total tweets collected so far: 4160\n",
      "Total tweets collected so far: 4170\n",
      "Total tweets collected so far: 4180\n",
      "Total tweets collected so far: 4190\n",
      "Total tweets collected so far: 4200\n",
      "Total tweets collected so far: 4210\n",
      "Total tweets collected so far: 4220\n",
      "Total tweets collected so far: 4230\n",
      "Total tweets collected so far: 4240\n",
      "Total tweets collected so far: 4250\n",
      "Total tweets collected so far: 4250\n",
      "Total tweets collected so far: 4260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 4270\n",
      "Total tweets collected so far: 4280\n",
      "Total tweets collected so far: 4290\n",
      "Total tweets collected so far: 4300\n",
      "Total tweets collected so far: 4310\n",
      "Total tweets collected so far: 4320\n",
      "Total tweets collected so far: 4330\n",
      "Total tweets collected so far: 4340\n",
      "Total tweets collected so far: 4350\n",
      "Total tweets collected so far: 4360\n",
      "Total tweets collected so far: 4370\n",
      "Total tweets collected so far: 4380\n",
      "Total tweets collected so far: 4390\n",
      "Total tweets collected so far: 4400\n",
      "Total tweets collected so far: 4410\n",
      "Total tweets collected so far: 4420\n",
      "Total tweets collected so far: 4430\n",
      "Total tweets collected so far: 4440\n",
      "Total tweets collected so far: 4450\n",
      "Total tweets collected so far: 4460\n",
      "Total tweets collected so far: 4470\n",
      "Total tweets collected so far: 4480\n",
      "Total tweets collected so far: 4490\n",
      "Total tweets collected so far: 4500\n",
      "Total tweets collected so far: 4500\n",
      "Total tweets collected so far: 4510\n",
      "Total tweets collected so far: 4520\n",
      "Total tweets collected so far: 4530\n",
      "Total tweets collected so far: 4540\n",
      "Total tweets collected so far: 4550\n",
      "Total tweets collected so far: 4560\n",
      "Total tweets collected so far: 4570\n",
      "Total tweets collected so far: 4580\n",
      "Total tweets collected so far: 4590\n",
      "Total tweets collected so far: 4600\n",
      "Total tweets collected so far: 4610\n",
      "Total tweets collected so far: 4620\n",
      "Total tweets collected so far: 4630\n",
      "Total tweets collected so far: 4640\n",
      "Total tweets collected so far: 4650\n",
      "Total tweets collected so far: 4660\n",
      "Total tweets collected so far: 4670\n",
      "Total tweets collected so far: 4680\n",
      "Total tweets collected so far: 4690\n",
      "Total tweets collected so far: 4700\n",
      "Total tweets collected so far: 4700\n",
      "Total tweets collected so far: 4710\n",
      "Total tweets collected so far: 4720\n",
      "Total tweets collected so far: 4730\n",
      "Total tweets collected so far: 4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n",
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 4750\n",
      "Total tweets collected so far: 4760\n",
      "Total tweets collected so far: 4770\n",
      "Total tweets collected so far: 4780\n",
      "Total tweets collected so far: 4790\n",
      "Total tweets collected so far: 4800\n",
      "Total tweets collected so far: 4810\n",
      "Total tweets collected so far: 4820\n",
      "Total tweets collected so far: 4830\n",
      "Total tweets collected so far: 4840\n",
      "Total tweets collected so far: 4850\n",
      "Total tweets collected so far: 4860\n",
      "Total tweets collected so far: 4870\n",
      "Total tweets collected so far: 4880\n",
      "Total tweets collected so far: 4890\n",
      "Total tweets collected so far: 4900\n",
      "Total tweets collected so far: 4910\n",
      "Total tweets collected so far: 4920\n",
      "Total tweets collected so far: 4930\n",
      "Total tweets collected so far: 4930\n",
      "Total tweets collected so far: 4940\n",
      "Total tweets collected so far: 4950\n",
      "Total tweets collected so far: 4960\n",
      "Total tweets collected so far: 4970\n",
      "Total tweets collected so far: 4980\n",
      "Total tweets collected so far: 4990\n",
      "Total tweets collected so far: 5000\n",
      "Total tweets collected so far: 5010\n",
      "Total tweets collected so far: 5020\n",
      "Total tweets collected so far: 5030\n",
      "Total tweets collected so far: 5040\n",
      "Total tweets collected so far: 5050\n",
      "Total tweets collected so far: 5060\n",
      "Total tweets collected so far: 5070\n",
      "Total tweets collected so far: 5080\n",
      "Total tweets collected so far: 5090\n",
      "Total tweets collected so far: 5100\n",
      "Total tweets collected so far: 5110\n",
      "Total tweets collected so far: 5120\n",
      "Total tweets collected so far: 5130\n",
      "Total tweets collected so far: 5140\n",
      "Total tweets collected so far: 5150\n",
      "Total tweets collected so far: 5150\n",
      "Total tweets collected so far: 5160\n",
      "Total tweets collected so far: 5170\n",
      "Total tweets collected so far: 5180\n",
      "Total tweets collected so far: 5190\n",
      "Total tweets collected so far: 5200\n",
      "Total tweets collected so far: 5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 5220\n",
      "Total tweets collected so far: 5230\n",
      "Total tweets collected so far: 5240\n",
      "Total tweets collected so far: 5250\n",
      "Total tweets collected so far: 5260\n",
      "Total tweets collected so far: 5270\n",
      "Total tweets collected so far: 5280\n",
      "Total tweets collected so far: 5290\n",
      "Total tweets collected so far: 5300\n",
      "Total tweets collected so far: 5310\n",
      "Total tweets collected so far: 5320\n",
      "Total tweets collected so far: 5330\n",
      "Total tweets collected so far: 5340\n",
      "Total tweets collected so far: 5350\n",
      "Total tweets collected so far: 5360\n",
      "Total tweets collected so far: 5370\n",
      "Total tweets collected so far: 5380\n",
      "Total tweets collected so far: 5390\n",
      "Total tweets collected so far: 5400\n",
      "Total tweets collected so far: 5410\n",
      "Total tweets collected so far: 5420\n",
      "Total tweets collected so far: 5430\n",
      "Total tweets collected so far: 5440\n",
      "Total tweets collected so far: 5450\n",
      "Total tweets collected so far: 5460\n",
      "Total tweets collected so far: 5470\n",
      "Total tweets collected so far: 5480\n",
      "Total tweets collected so far: 5490\n",
      "Total tweets collected so far: 5500\n",
      "Total tweets collected so far: 5510\n",
      "Total tweets collected so far: 5520\n",
      "Total tweets collected so far: 5530\n",
      "Total tweets collected so far: 5540\n",
      "Total tweets collected so far: 5550\n",
      "Total tweets collected so far: 5560\n",
      "Total tweets collected so far: 5570\n",
      "Total tweets collected so far: 5580\n",
      "Total tweets collected so far: 5590\n",
      "Total tweets collected so far: 5600\n",
      "Total tweets collected so far: 5610\n",
      "Total tweets collected so far: 5620\n",
      "Total tweets collected so far: 5630\n",
      "Total tweets collected so far: 5640\n",
      "Total tweets collected so far: 5650\n",
      "Total tweets collected so far: 5660\n",
      "Total tweets collected so far: 5670\n",
      "Total tweets collected so far: 5680\n",
      "Total tweets collected so far: 5680\n",
      "Total tweets collected so far: 5680\n",
      "Total tweets collected so far: 5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n",
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 5690\n",
      "Total tweets collected so far: 5700\n",
      "Total tweets collected so far: 5710\n",
      "Total tweets collected so far: 5720\n",
      "Total tweets collected so far: 5730\n",
      "Total tweets collected so far: 5730\n",
      "Total tweets collected so far: 5740\n",
      "Total tweets collected so far: 5740\n",
      "Total tweets collected so far: 5750\n",
      "Total tweets collected so far: 5760\n",
      "Total tweets collected so far: 5770\n",
      "Total tweets collected so far: 5780\n",
      "Total tweets collected so far: 5790\n",
      "Total tweets collected so far: 5800\n",
      "Total tweets collected so far: 5810\n",
      "Total tweets collected so far: 5820\n",
      "Total tweets collected so far: 5830\n",
      "Total tweets collected so far: 5840\n",
      "Total tweets collected so far: 5850\n",
      "Total tweets collected so far: 5860\n",
      "Total tweets collected so far: 5870\n",
      "Total tweets collected so far: 5880\n",
      "Total tweets collected so far: 5890\n",
      "Total tweets collected so far: 5900\n",
      "Total tweets collected so far: 5910\n",
      "Total tweets collected so far: 5920\n",
      "Total tweets collected so far: 5930\n",
      "Total tweets collected so far: 5940\n",
      "Total tweets collected so far: 5950\n",
      "Total tweets collected so far: 5960\n",
      "Total tweets collected so far: 5970\n",
      "Total tweets collected so far: 5980\n",
      "Total tweets collected so far: 5980\n",
      "Total tweets collected so far: 5990\n",
      "Total tweets collected so far: 6000\n",
      "Total tweets collected so far: 6000\n",
      "Total tweets collected so far: 6010\n",
      "Total tweets collected so far: 6020\n",
      "Total tweets collected so far: 6030\n",
      "Total tweets collected so far: 6040\n",
      "Total tweets collected so far: 6050\n",
      "Total tweets collected so far: 6060\n",
      "Total tweets collected so far: 6070\n",
      "Total tweets collected so far: 6080\n",
      "Total tweets collected so far: 6090\n",
      "Total tweets collected so far: 6100\n",
      "Total tweets collected so far: 6110\n",
      "Total tweets collected so far: 6120\n",
      "Total tweets collected so far: 6130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 6140\n",
      "Total tweets collected so far: 6150\n",
      "Total tweets collected so far: 6160\n",
      "Total tweets collected so far: 6170\n",
      "Total tweets collected so far: 6180\n",
      "Total tweets collected so far: 6190\n",
      "Total tweets collected so far: 6190\n",
      "Total tweets collected so far: 6200\n",
      "Total tweets collected so far: 6210\n",
      "Total tweets collected so far: 6220\n",
      "Total tweets collected so far: 6230\n",
      "Total tweets collected so far: 6240\n",
      "Total tweets collected so far: 6250\n",
      "Total tweets collected so far: 6260\n",
      "Total tweets collected so far: 6270\n",
      "Total tweets collected so far: 6280\n",
      "Total tweets collected so far: 6290\n",
      "Total tweets collected so far: 6290\n",
      "Total tweets collected so far: 6300\n",
      "Total tweets collected so far: 6310\n",
      "Total tweets collected so far: 6320\n",
      "Total tweets collected so far: 6330\n",
      "Total tweets collected so far: 6340\n",
      "Total tweets collected so far: 6350\n",
      "Total tweets collected so far: 6360\n",
      "Total tweets collected so far: 6370\n",
      "Total tweets collected so far: 6380\n",
      "Total tweets collected so far: 6390\n",
      "Total tweets collected so far: 6390\n",
      "Total tweets collected so far: 6400\n",
      "Total tweets collected so far: 6410\n",
      "Total tweets collected so far: 6420\n",
      "Total tweets collected so far: 6430\n",
      "Total tweets collected so far: 6440\n",
      "Total tweets collected so far: 6450\n",
      "Total tweets collected so far: 6460\n",
      "Total tweets collected so far: 6470\n",
      "Total tweets collected so far: 6480\n",
      "Total tweets collected so far: 6490\n",
      "Total tweets collected so far: 6500\n",
      "Total tweets collected so far: 6500\n",
      "Total tweets collected so far: 6510\n",
      "Total tweets collected so far: 6520\n",
      "Total tweets collected so far: 6530\n",
      "Total tweets collected so far: 6540\n",
      "Total tweets collected so far: 6550\n",
      "Total tweets collected so far: 6560\n",
      "Total tweets collected so far: 6570\n",
      "Total tweets collected so far: 6580\n",
      "Total tweets collected so far: 6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n",
      "Waiting for 5 minutes: 100%|██████████████████████████████████████████████████████████| 300/300 [05:00<00:00,  1.00s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 6590\n",
      "Total tweets collected so far: 6590\n",
      "Total tweets collected so far: 6600\n",
      "Total tweets collected so far: 6610\n",
      "Total tweets collected so far: 6620\n",
      "Total tweets collected so far: 6630\n",
      "Total tweets collected so far: 6640\n",
      "Total tweets collected so far: 6650\n",
      "Total tweets collected so far: 6660\n",
      "Total tweets collected so far: 6670\n",
      "Total tweets collected so far: 6680\n",
      "Total tweets collected so far: 6690\n",
      "Total tweets collected so far: 6700\n",
      "Total tweets collected so far: 6710\n",
      "Total tweets collected so far: 6710\n",
      "Total tweets collected so far: 6720\n",
      "Total tweets collected so far: 6730\n",
      "Total tweets collected so far: 6740\n",
      "Total tweets collected so far: 6750\n",
      "Total tweets collected so far: 6760\n",
      "Total tweets collected so far: 6770\n",
      "Total tweets collected so far: 6780\n",
      "Total tweets collected so far: 6790\n",
      "Total tweets collected so far: 6800\n",
      "Total tweets collected so far: 6810\n",
      "Total tweets collected so far: 6820\n",
      "Total tweets collected so far: 6830\n",
      "Total tweets collected so far: 6840\n",
      "Total tweets collected so far: 6850\n",
      "Total tweets collected so far: 6860\n",
      "Total tweets collected so far: 6870\n",
      "Total tweets collected so far: 6880\n",
      "Total tweets collected so far: 6890\n",
      "Total tweets collected so far: 6900\n",
      "Total tweets collected so far: 6910\n",
      "Total tweets collected so far: 6920\n",
      "Total tweets collected so far: 6920\n",
      "Total tweets collected so far: 6920\n",
      "Total tweets collected so far: 6930\n",
      "Total tweets collected so far: 6940\n",
      "Total tweets collected so far: 6950\n",
      "Total tweets collected so far: 6960\n",
      "Total tweets collected so far: 6970\n",
      "Total tweets collected so far: 6980\n",
      "Total tweets collected so far: 6990\n",
      "Total tweets collected so far: 6990\n",
      "Total tweets collected so far: 7000\n",
      "Total tweets collected so far: 7010\n",
      "Finished collecting tweets. Total tweets collected: 7010\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MINIMUM_TWEETS = 10\n",
    "START_DATE = datetime(2022, 1, 1)  # Start date of the range\n",
    "END_DATE = datetime(2023, 12, 31)  # End date of the range\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Delay between requests in seconds\n",
    "CSV_FILE = 'HDFC_Bank.csv'  # Updated file for HDFC Bank data\n",
    "SUMMARY_FILE = 'HDFC_Bank_Collection_Summary.csv'  # Updated summary file for HDFC Bank\n",
    "\n",
    "# Initialize Twitter client\n",
    "client = Client()  # Initialize your Twitter client\n",
    "client.load_cookies('cookies.json')\n",
    "cookies_file = 'cookies.json'\n",
    "cookies2_file = 'cookies2.json'\n",
    "current_cookies = cookies_file\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='hdfc_bank_tweet_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize counters\n",
    "total_tweets_collected = 0\n",
    "daily_stats = []\n",
    "\n",
    "def switch_cookies():\n",
    "    \"\"\"Switches between cookies.json and cookies2.json.\"\"\"\n",
    "    global current_cookies\n",
    "    if current_cookies == cookies_file:\n",
    "        client.load_cookies(cookies2_file)\n",
    "        current_cookies = cookies2_file\n",
    "    else:\n",
    "        client.load_cookies(cookies_file)\n",
    "        current_cookies = cookies_file\n",
    "    logging.info(f'Switched to {current_cookies}.')\n",
    "\n",
    "def get_tweets(query, tweets):\n",
    "    if tweets is None:\n",
    "        logging.info(f'Getting tweets for query: {query}...')\n",
    "        tweets = client.search_tweet(query, product='Top')\n",
    "    else:\n",
    "        wait_time = randint(5, 10)\n",
    "        logging.info(f'Getting next tweets after {wait_time} seconds ...')\n",
    "        time.sleep(wait_time)\n",
    "        tweets = tweets.next()\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def construct_query(date):\n",
    "    next_day = date + timedelta(days=1)\n",
    "    query = (f'(HDFC OR \"HDFC Bank\" OR #HDFC OR #HDFCBank OR '\n",
    "             f'Stock OR Market OR #StockMarket OR #MarketAnalysis) '\n",
    "             f'lang:en until:{next_day.strftime(\"%Y-%m-%d\")} since:{date.strftime(\"%Y-%m-%d\")}')\n",
    "    return query\n",
    "\n",
    "def delay_for_minutes(minutes=5):\n",
    "    \"\"\"Delays for the specified number of minutes, showing progress with tqdm.\"\"\"\n",
    "    wait_time = minutes * 60  # Convert minutes to seconds\n",
    "    with tqdm(total=wait_time, desc=f'Waiting for {minutes} minutes', unit='s', leave=True) as rate_pbar:\n",
    "        for _ in range(wait_time):\n",
    "            time.sleep(1)\n",
    "            rate_pbar.update(1)\n",
    "\n",
    "def collect_tweets_for_day(date):\n",
    "    global total_tweets_collected\n",
    "    query = construct_query(date)\n",
    "    tweet_count = 0\n",
    "    tweets = None\n",
    "    daily_tweet_data = []\n",
    "    \n",
    "    while tweet_count < MINIMUM_TWEETS:\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "        except TooManyRequests as e:\n",
    "            rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "            current_time = datetime.now()\n",
    "            wait_time = (rate_limit_reset - current_time).total_seconds()\n",
    "            \n",
    "            # Switch cookies and retry\n",
    "            logging.warning(f'Rate limit reached. Switching cookies.')\n",
    "            switch_cookies()  # Logging cookie switch\n",
    "\n",
    "            # Retry immediately with new cookies\n",
    "            try:\n",
    "                tweets = get_tweets(query, tweets)\n",
    "                logging.info('Successfully resumed after switching cookies.')\n",
    "            except TooManyRequests as e:\n",
    "                logging.warning(f'Rate limit still in place even after switching cookies.')\n",
    "                if wait_time > 0:\n",
    "                    logging.warning(f'Waiting until {rate_limit_reset}')\n",
    "                    delay_for_minutes(5)  # Reduced to 5 minutes\n",
    "                else:\n",
    "                    logging.warning(f'Rate limit reset time is in the past. Waiting for 5 minutes as a precaution.')\n",
    "                    delay_for_minutes(5)\n",
    "            continue\n",
    "\n",
    "        if not tweets:\n",
    "            logging.info(f'No more tweets found for {date.strftime(\"%Y-%m-%d\")}')\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if tweet_count >= MINIMUM_TWEETS:\n",
    "                break\n",
    "            tweet_count += 1\n",
    "            total_tweets_collected += 1\n",
    "            daily_tweet_data.append([date.strftime('%Y-%m-%d'), tweet_count, tweet.user.name, tweet.text, tweet.created_at, tweet.retweet_count, tweet.favorite_count])\n",
    "\n",
    "        logging.info(f'Got {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}')\n",
    "        daily_stats.append([date.strftime('%Y-%m-%d'), tweet_count])\n",
    "    \n",
    "    # Write daily tweet data to CSV after processing all tweets for the day\n",
    "    with open(CSV_FILE, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(daily_tweet_data)\n",
    "\n",
    "    if tweet_count < MINIMUM_TWEETS:\n",
    "        logging.warning(f'Collected {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}, which is less than the minimum of {MINIMUM_TWEETS}')\n",
    "    \n",
    "    logging.info(f'Done for {date.strftime(\"%Y-%m-%d\")}')\n",
    "    print(f'Total tweets collected so far: {total_tweets_collected}')\n",
    "\n",
    "def get_last_collected_date():\n",
    "    \"\"\"Reads the CSV file to find the last collected date.\"\"\"\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        return START_DATE\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        if len(rows) > 1:\n",
    "            last_date = rows[-1][0]\n",
    "            return datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    return START_DATE\n",
    "\n",
    "# Write header to the CSV file if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweet Count', 'Username', 'Text', 'Created At', 'Retweets', 'Likes'])\n",
    "\n",
    "# Get the starting date\n",
    "start_date = get_last_collected_date()\n",
    "if start_date > END_DATE:\n",
    "    print(f'All data has already been collected up to {END_DATE.strftime(\"%Y-%m-%d\")}.')\n",
    "else:\n",
    "    # Collect tweets for the specified date range\n",
    "    current_date = start_date\n",
    "    while current_date <= END_DATE:\n",
    "        collect_tweets_for_day(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    print(f'Finished collecting tweets. Total tweets collected: {total_tweets_collected}')\n",
    "\n",
    "    # Save summary to a CSV file\n",
    "    with open(SUMMARY_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweets Collected'])\n",
    "        writer.writerows(daily_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893fcf66-d0ab-4a13-9414-fe6114278aa1",
   "metadata": {},
   "source": [
    "# INFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233aaa2f-9b44-4afe-b43a-e431db36ea2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets collected so far: 0\n",
      "Total tweets collected so far: 10\n",
      "Total tweets collected so far: 20\n",
      "Total tweets collected so far: 30\n",
      "Total tweets collected so far: 40\n",
      "Total tweets collected so far: 50\n",
      "Total tweets collected so far: 50\n",
      "Total tweets collected so far: 60\n",
      "Total tweets collected so far: 70\n",
      "Total tweets collected so far: 80\n",
      "Total tweets collected so far: 90\n",
      "Total tweets collected so far: 100\n",
      "Total tweets collected so far: 110\n",
      "Total tweets collected so far: 120\n",
      "Total tweets collected so far: 130\n",
      "Total tweets collected so far: 140\n",
      "Total tweets collected so far: 140\n",
      "Total tweets collected so far: 150\n",
      "Total tweets collected so far: 160\n",
      "Total tweets collected so far: 160\n",
      "Total tweets collected so far: 170\n",
      "Total tweets collected so far: 180\n",
      "Total tweets collected so far: 190\n",
      "Total tweets collected so far: 200\n",
      "Total tweets collected so far: 210\n",
      "Total tweets collected so far: 210\n",
      "Total tweets collected so far: 220\n",
      "Total tweets collected so far: 230\n",
      "Total tweets collected so far: 240\n",
      "Total tweets collected so far: 250\n",
      "Total tweets collected so far: 260\n",
      "Total tweets collected so far: 270\n",
      "Total tweets collected so far: 280\n",
      "Total tweets collected so far: 290\n",
      "Total tweets collected so far: 300\n",
      "Total tweets collected so far: 300\n",
      "Total tweets collected so far: 310\n",
      "Total tweets collected so far: 320\n",
      "Total tweets collected so far: 320\n",
      "Total tweets collected so far: 330\n",
      "Total tweets collected so far: 340\n",
      "Total tweets collected so far: 350\n",
      "Total tweets collected so far: 360\n",
      "Total tweets collected so far: 370\n",
      "Total tweets collected so far: 380\n",
      "Total tweets collected so far: 390\n",
      "Total tweets collected so far: 400\n",
      "Total tweets collected so far: 410\n",
      "Total tweets collected so far: 420\n",
      "Total tweets collected so far: 430\n",
      "Total tweets collected so far: 430\n",
      "Total tweets collected so far: 440\n",
      "Total tweets collected so far: 450\n",
      "Total tweets collected so far: 460\n",
      "Total tweets collected so far: 470\n",
      "Total tweets collected so far: 480\n",
      "Total tweets collected so far: 490\n",
      "Total tweets collected so far: 500\n",
      "Total tweets collected so far: 510\n",
      "Total tweets collected so far: 520\n",
      "Total tweets collected so far: 530\n",
      "Total tweets collected so far: 530\n",
      "Total tweets collected so far: 530\n",
      "Total tweets collected so far: 540\n",
      "Total tweets collected so far: 550\n",
      "Total tweets collected so far: 560\n",
      "Total tweets collected so far: 570\n",
      "Total tweets collected so far: 580\n",
      "Total tweets collected so far: 580\n",
      "Total tweets collected so far: 580\n",
      "Total tweets collected so far: 580\n",
      "Total tweets collected so far: 590\n",
      "Total tweets collected so far: 600\n",
      "Total tweets collected so far: 610\n",
      "Total tweets collected so far: 620\n",
      "Total tweets collected so far: 630\n",
      "Total tweets collected so far: 630\n",
      "Total tweets collected so far: 640\n",
      "Total tweets collected so far: 650\n",
      "Total tweets collected so far: 660\n",
      "Total tweets collected so far: 670\n",
      "Total tweets collected so far: 680\n",
      "Total tweets collected so far: 690\n",
      "Total tweets collected so far: 700\n",
      "Total tweets collected so far: 710\n",
      "Total tweets collected so far: 720\n",
      "Total tweets collected so far: 730\n",
      "Total tweets collected so far: 730\n",
      "Total tweets collected so far: 740\n",
      "Total tweets collected so far: 740\n",
      "Total tweets collected so far: 750\n",
      "Total tweets collected so far: 760\n",
      "Total tweets collected so far: 770\n",
      "Total tweets collected so far: 780\n",
      "Total tweets collected so far: 790\n",
      "Total tweets collected so far: 800\n",
      "Total tweets collected so far: 810\n",
      "Total tweets collected so far: 820\n",
      "Total tweets collected so far: 830\n",
      "Total tweets collected so far: 840\n",
      "Total tweets collected so far: 850\n",
      "Total tweets collected so far: 850\n",
      "Total tweets collected so far: 850\n",
      "Total tweets collected so far: 860\n",
      "Total tweets collected so far: 870\n",
      "Total tweets collected so far: 880\n",
      "Total tweets collected so far: 890\n",
      "Total tweets collected so far: 900\n",
      "Total tweets collected so far: 910\n",
      "Total tweets collected so far: 910\n",
      "Total tweets collected so far: 920\n",
      "Total tweets collected so far: 930\n",
      "Total tweets collected so far: 940\n",
      "Total tweets collected so far: 950\n",
      "Total tweets collected so far: 960\n",
      "Total tweets collected so far: 970\n",
      "Total tweets collected so far: 980\n",
      "Total tweets collected so far: 990\n",
      "Total tweets collected so far: 1000\n",
      "Total tweets collected so far: 1010\n",
      "Total tweets collected so far: 1020\n",
      "Total tweets collected so far: 1020\n",
      "Total tweets collected so far: 1030\n",
      "Total tweets collected so far: 1040\n",
      "Total tweets collected so far: 1050\n",
      "Total tweets collected so far: 1060\n",
      "Total tweets collected so far: 1060\n",
      "Total tweets collected so far: 1070\n",
      "Total tweets collected so far: 1080\n",
      "Total tweets collected so far: 1090\n",
      "Total tweets collected so far: 1100\n",
      "Total tweets collected so far: 1110\n",
      "Total tweets collected so far: 1120\n",
      "Total tweets collected so far: 1120\n",
      "Total tweets collected so far: 1120\n",
      "Total tweets collected so far: 1130\n",
      "Total tweets collected so far: 1130\n",
      "Total tweets collected so far: 1140\n",
      "Total tweets collected so far: 1150\n",
      "Total tweets collected so far: 1160\n",
      "Total tweets collected so far: 1170\n",
      "Total tweets collected so far: 1180\n",
      "Total tweets collected so far: 1190\n",
      "Total tweets collected so far: 1200\n",
      "Total tweets collected so far: 1210\n",
      "Total tweets collected so far: 1220\n",
      "Total tweets collected so far: 1230\n",
      "Total tweets collected so far: 1240\n",
      "Total tweets collected so far: 1250\n",
      "Total tweets collected so far: 1260\n",
      "Total tweets collected so far: 1270\n",
      "Total tweets collected so far: 1280\n",
      "Total tweets collected so far: 1290\n",
      "Total tweets collected so far: 1300\n",
      "Total tweets collected so far: 1300\n",
      "Total tweets collected so far: 1310\n",
      "Total tweets collected so far: 1320\n",
      "Total tweets collected so far: 1330\n",
      "Total tweets collected so far: 1340\n",
      "Total tweets collected so far: 1350\n",
      "Total tweets collected so far: 1350\n",
      "Total tweets collected so far: 1360\n",
      "Total tweets collected so far: 1370\n",
      "Total tweets collected so far: 1380\n",
      "Total tweets collected so far: 1390\n",
      "Total tweets collected so far: 1400\n",
      "Total tweets collected so far: 1410\n",
      "Total tweets collected so far: 1420\n",
      "Total tweets collected so far: 1430\n",
      "Total tweets collected so far: 1440\n",
      "Total tweets collected so far: 1450\n",
      "Total tweets collected so far: 1460\n",
      "Total tweets collected so far: 1470\n",
      "Total tweets collected so far: 1470\n",
      "Total tweets collected so far: 1480\n",
      "Total tweets collected so far: 1490\n",
      "Total tweets collected so far: 1500\n",
      "Total tweets collected so far: 1500\n",
      "Total tweets collected so far: 1500\n",
      "Total tweets collected so far: 1500\n",
      "Total tweets collected so far: 1510\n",
      "Total tweets collected so far: 1520\n",
      "Total tweets collected so far: 1530\n",
      "Total tweets collected so far: 1540\n",
      "Total tweets collected so far: 1550\n",
      "Total tweets collected so far: 1560\n",
      "Total tweets collected so far: 1570\n",
      "Total tweets collected so far: 1580\n",
      "Total tweets collected so far: 1590\n",
      "Total tweets collected so far: 1590\n",
      "Total tweets collected so far: 1600\n",
      "Total tweets collected so far: 1610\n",
      "Total tweets collected so far: 1620\n",
      "Total tweets collected so far: 1630\n",
      "Total tweets collected so far: 1640\n",
      "Total tweets collected so far: 1650\n",
      "Total tweets collected so far: 1660\n",
      "Total tweets collected so far: 1670\n",
      "Total tweets collected so far: 1680\n",
      "Total tweets collected so far: 1690\n",
      "Total tweets collected so far: 1700\n",
      "Total tweets collected so far: 1710\n",
      "Total tweets collected so far: 1720\n",
      "Total tweets collected so far: 1730\n",
      "Total tweets collected so far: 1740\n",
      "Total tweets collected so far: 1750\n",
      "Total tweets collected so far: 1760\n",
      "Total tweets collected so far: 1770\n",
      "Total tweets collected so far: 1780\n",
      "Total tweets collected so far: 1780\n",
      "Total tweets collected so far: 1790\n",
      "Total tweets collected so far: 1800\n",
      "Total tweets collected so far: 1810\n",
      "Total tweets collected so far: 1820\n",
      "Total tweets collected so far: 1830\n",
      "Total tweets collected so far: 1830\n",
      "Total tweets collected so far: 1840\n",
      "Total tweets collected so far: 1850\n",
      "Total tweets collected so far: 1860\n",
      "Total tweets collected so far: 1870\n",
      "Total tweets collected so far: 1870\n",
      "Total tweets collected so far: 1880\n",
      "Total tweets collected so far: 1890\n",
      "Total tweets collected so far: 1900\n",
      "Total tweets collected so far: 1910\n",
      "Total tweets collected so far: 1920\n",
      "Total tweets collected so far: 1930\n",
      "Total tweets collected so far: 1940\n",
      "Total tweets collected so far: 1950\n",
      "Total tweets collected so far: 1960\n",
      "Total tweets collected so far: 1960\n",
      "Total tweets collected so far: 1970\n",
      "Total tweets collected so far: 1980\n",
      "Total tweets collected so far: 1990\n",
      "Total tweets collected so far: 2000\n",
      "Total tweets collected so far: 2010\n",
      "Total tweets collected so far: 2020\n",
      "Total tweets collected so far: 2030\n",
      "Total tweets collected so far: 2040\n",
      "Total tweets collected so far: 2050\n",
      "Total tweets collected so far: 2060\n",
      "Total tweets collected so far: 2060\n",
      "Total tweets collected so far: 2070\n",
      "Total tweets collected so far: 2080\n",
      "Total tweets collected so far: 2090\n",
      "Total tweets collected so far: 2100\n",
      "Total tweets collected so far: 2110\n",
      "Total tweets collected so far: 2120\n",
      "Total tweets collected so far: 2120\n",
      "Total tweets collected so far: 2130\n",
      "Total tweets collected so far: 2140\n",
      "Total tweets collected so far: 2150\n",
      "Total tweets collected so far: 2160\n",
      "Total tweets collected so far: 2170\n",
      "Total tweets collected so far: 2180\n",
      "Total tweets collected so far: 2190\n",
      "Total tweets collected so far: 2200\n",
      "Total tweets collected so far: 2210\n",
      "Total tweets collected so far: 2210\n",
      "Total tweets collected so far: 2220\n",
      "Total tweets collected so far: 2230\n",
      "Total tweets collected so far: 2240\n",
      "Total tweets collected so far: 2250\n",
      "Total tweets collected so far: 2260\n",
      "Total tweets collected so far: 2270\n",
      "Total tweets collected so far: 2280\n",
      "Total tweets collected so far: 2290\n",
      "Total tweets collected so far: 2300\n",
      "Total tweets collected so far: 2310\n",
      "Total tweets collected so far: 2320\n",
      "Total tweets collected so far: 2330\n",
      "Total tweets collected so far: 2340\n",
      "Total tweets collected so far: 2350\n",
      "Total tweets collected so far: 2360\n",
      "Total tweets collected so far: 2370\n",
      "Total tweets collected so far: 2380\n",
      "Total tweets collected so far: 2390\n",
      "Total tweets collected so far: 2400\n",
      "Total tweets collected so far: 2410\n",
      "Total tweets collected so far: 2420\n",
      "Total tweets collected so far: 2430\n",
      "Total tweets collected so far: 2440\n",
      "Total tweets collected so far: 2450\n",
      "Total tweets collected so far: 2460\n",
      "Total tweets collected so far: 2470\n",
      "Total tweets collected so far: 2480\n",
      "Total tweets collected so far: 2480\n",
      "Total tweets collected so far: 2490\n",
      "Total tweets collected so far: 2500\n",
      "Total tweets collected so far: 2510\n",
      "Total tweets collected so far: 2520\n",
      "Total tweets collected so far: 2530\n",
      "Total tweets collected so far: 2540\n",
      "Total tweets collected so far: 2550\n",
      "Total tweets collected so far: 2560\n",
      "Total tweets collected so far: 2570\n",
      "Total tweets collected so far: 2580\n",
      "Total tweets collected so far: 2590\n",
      "Total tweets collected so far: 2600\n",
      "Total tweets collected so far: 2610\n",
      "Total tweets collected so far: 2620\n",
      "Total tweets collected so far: 2630\n",
      "Total tweets collected so far: 2640\n",
      "Total tweets collected so far: 2650\n",
      "Total tweets collected so far: 2660\n",
      "Total tweets collected so far: 2670\n",
      "Total tweets collected so far: 2680\n",
      "Total tweets collected so far: 2690\n",
      "Total tweets collected so far: 2700\n",
      "Total tweets collected so far: 2710\n",
      "Total tweets collected so far: 2720\n",
      "Total tweets collected so far: 2730\n",
      "Total tweets collected so far: 2740\n",
      "Total tweets collected so far: 2750\n",
      "Total tweets collected so far: 2750\n",
      "Total tweets collected so far: 2760\n",
      "Total tweets collected so far: 2770\n",
      "Total tweets collected so far: 2780\n",
      "Total tweets collected so far: 2780\n",
      "Total tweets collected so far: 2790\n",
      "Total tweets collected so far: 2800\n",
      "Total tweets collected so far: 2810\n",
      "Total tweets collected so far: 2820\n",
      "Total tweets collected so far: 2830\n",
      "Total tweets collected so far: 2840\n",
      "Total tweets collected so far: 2850\n",
      "Total tweets collected so far: 2860\n",
      "Total tweets collected so far: 2870\n",
      "Total tweets collected so far: 2880\n",
      "Total tweets collected so far: 2890\n",
      "Total tweets collected so far: 2900\n",
      "Total tweets collected so far: 2910\n",
      "Total tweets collected so far: 2920\n",
      "Total tweets collected so far: 2930\n",
      "Total tweets collected so far: 2940\n",
      "Total tweets collected so far: 2940\n",
      "Total tweets collected so far: 2950\n",
      "Total tweets collected so far: 2960\n",
      "Total tweets collected so far: 2970\n",
      "Total tweets collected so far: 2980\n",
      "Total tweets collected so far: 2990\n",
      "Total tweets collected so far: 2990\n",
      "Total tweets collected so far: 2990\n",
      "Total tweets collected so far: 3000\n",
      "Total tweets collected so far: 3010\n",
      "Total tweets collected so far: 3020\n",
      "Total tweets collected so far: 3030\n",
      "Total tweets collected so far: 3040\n",
      "Total tweets collected so far: 3050\n",
      "Total tweets collected so far: 3060\n",
      "Total tweets collected so far: 3070\n",
      "Total tweets collected so far: 3080\n",
      "Total tweets collected so far: 3090\n",
      "Total tweets collected so far: 3100\n",
      "Total tweets collected so far: 3110\n",
      "Total tweets collected so far: 3120\n",
      "Total tweets collected so far: 3130\n",
      "Total tweets collected so far: 3140\n",
      "Total tweets collected so far: 3150\n",
      "Total tweets collected so far: 3160\n",
      "Total tweets collected so far: 3170\n",
      "Total tweets collected so far: 3180\n",
      "Total tweets collected so far: 3190\n",
      "Total tweets collected so far: 3200\n",
      "Total tweets collected so far: 3200\n",
      "Total tweets collected so far: 3200\n",
      "Total tweets collected so far: 3210\n",
      "Total tweets collected so far: 3220\n",
      "Total tweets collected so far: 3230\n",
      "Total tweets collected so far: 3240\n",
      "Total tweets collected so far: 3250\n",
      "Total tweets collected so far: 3250\n",
      "Total tweets collected so far: 3260\n",
      "Total tweets collected so far: 3270\n",
      "Total tweets collected so far: 3280\n",
      "Total tweets collected so far: 3290\n",
      "Total tweets collected so far: 3300\n",
      "Total tweets collected so far: 3310\n",
      "Total tweets collected so far: 3320\n",
      "Total tweets collected so far: 3330\n",
      "Total tweets collected so far: 3340\n",
      "Total tweets collected so far: 3350\n",
      "Total tweets collected so far: 3360\n",
      "Total tweets collected so far: 3370\n",
      "Total tweets collected so far: 3380\n",
      "Total tweets collected so far: 3390\n",
      "Total tweets collected so far: 3400\n",
      "Total tweets collected so far: 3410\n",
      "Total tweets collected so far: 3420\n",
      "Total tweets collected so far: 3430\n",
      "Total tweets collected so far: 3440\n",
      "Total tweets collected so far: 3450\n",
      "Total tweets collected so far: 3460\n",
      "Total tweets collected so far: 3470\n",
      "Total tweets collected so far: 3470\n",
      "Total tweets collected so far: 3480\n",
      "Total tweets collected so far: 3490\n",
      "Total tweets collected so far: 3490\n",
      "Total tweets collected so far: 3500\n",
      "Total tweets collected so far: 3510\n",
      "Total tweets collected so far: 3510\n",
      "Total tweets collected so far: 3520\n",
      "Total tweets collected so far: 3530\n",
      "Total tweets collected so far: 3530\n",
      "Total tweets collected so far: 3540\n",
      "Total tweets collected so far: 3550\n",
      "Total tweets collected so far: 3560\n",
      "Total tweets collected so far: 3570\n",
      "Total tweets collected so far: 3580\n",
      "Total tweets collected so far: 3590\n",
      "Total tweets collected so far: 3600\n",
      "Total tweets collected so far: 3610\n",
      "Total tweets collected so far: 3620\n",
      "Total tweets collected so far: 3630\n",
      "Total tweets collected so far: 3630\n",
      "Total tweets collected so far: 3640\n",
      "Total tweets collected so far: 3640\n",
      "Total tweets collected so far: 3650\n",
      "Total tweets collected so far: 3660\n",
      "Total tweets collected so far: 3670\n",
      "Total tweets collected so far: 3680\n",
      "Total tweets collected so far: 3690\n",
      "Total tweets collected so far: 3700\n",
      "Total tweets collected so far: 3710\n",
      "Total tweets collected so far: 3720\n",
      "Total tweets collected so far: 3730\n",
      "Total tweets collected so far: 3740\n",
      "Total tweets collected so far: 3750\n",
      "Total tweets collected so far: 3760\n",
      "Total tweets collected so far: 3760\n",
      "Total tweets collected so far: 3770\n",
      "Total tweets collected so far: 3780\n",
      "Total tweets collected so far: 3790\n",
      "Total tweets collected so far: 3800\n",
      "Total tweets collected so far: 3810\n",
      "Total tweets collected so far: 3810\n",
      "Total tweets collected so far: 3820\n",
      "Total tweets collected so far: 3820\n",
      "Total tweets collected so far: 3830\n",
      "Total tweets collected so far: 3830\n",
      "Total tweets collected so far: 3840\n",
      "Total tweets collected so far: 3850\n",
      "Total tweets collected so far: 3860\n",
      "Total tweets collected so far: 3870\n",
      "Total tweets collected so far: 3880\n",
      "Total tweets collected so far: 3890\n",
      "Total tweets collected so far: 3900\n",
      "Total tweets collected so far: 3910\n",
      "Total tweets collected so far: 3920\n",
      "Total tweets collected so far: 3930\n",
      "Total tweets collected so far: 3940\n",
      "Total tweets collected so far: 3950\n",
      "Total tweets collected so far: 3960\n",
      "Total tweets collected so far: 3970\n",
      "Total tweets collected so far: 3970\n",
      "Total tweets collected so far: 3980\n",
      "Total tweets collected so far: 3990\n",
      "Total tweets collected so far: 4000\n",
      "Total tweets collected so far: 4010\n",
      "Total tweets collected so far: 4020\n",
      "Total tweets collected so far: 4030\n",
      "Total tweets collected so far: 4040\n",
      "Total tweets collected so far: 4050\n",
      "Total tweets collected so far: 4060\n",
      "Total tweets collected so far: 4070\n",
      "Total tweets collected so far: 4080\n",
      "Total tweets collected so far: 4090\n",
      "Finished collecting tweets. Total tweets collected: 4090\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MINIMUM_TWEETS = 10\n",
    "START_DATE = datetime(2022, 1, 1)  # Start date of the range\n",
    "END_DATE = datetime(2023, 12, 31)  # End date of the range\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Delay between requests in seconds\n",
    "CSV_FILE = 'INFY.csv'  # Updated file for Infosys data\n",
    "SUMMARY_FILE = 'INFY_Collection_Summary.csv'  # Updated summary file for Infosys\n",
    "\n",
    "# Initialize Twitter client\n",
    "client = Client()  # Initialize your Twitter client\n",
    "cookies_files = ['cookies.json', 'cookies2.json', 'cookies3.json', 'cookies4.json']\n",
    "current_cookie_index = 0\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='infy_tweet_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize counters\n",
    "total_tweets_collected = 0\n",
    "daily_stats = []\n",
    "\n",
    "def switch_cookies():\n",
    "    \"\"\"Switches between cookies.\"\"\"\n",
    "    global current_cookie_index\n",
    "    current_cookie_index = (current_cookie_index + 1) % len(cookies_files)\n",
    "    client.load_cookies(cookies_files[current_cookie_index])\n",
    "    logging.info(f'Switched to {cookies_files[current_cookie_index]}.')\n",
    "\n",
    "def get_tweets(query, tweets):\n",
    "    try:\n",
    "        if tweets is None:\n",
    "            logging.info(f'Getting tweets for query: {query}...')\n",
    "            tweets = client.search_tweet(query, product='Top')\n",
    "        else:\n",
    "            wait_time = randint(5, 10)\n",
    "            logging.info(f'Getting next tweets after {wait_time} seconds ...')\n",
    "            time.sleep(wait_time)\n",
    "            tweets = tweets.next()\n",
    "    except TooManyRequests as e:\n",
    "        rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "        current_time = datetime.now()\n",
    "        wait_time = (rate_limit_reset - current_time).total_seconds()\n",
    "        \n",
    "        logging.warning(f'Rate limit reached. Switching cookies.')\n",
    "        switch_cookies()  # Logging cookie switch\n",
    "\n",
    "        # Retry with new cookies\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "            logging.info('Successfully resumed after switching cookies.')\n",
    "        except TooManyRequests as e:\n",
    "            logging.warning(f'Rate limit still in place even after switching cookies.')\n",
    "            if wait_time > 0:\n",
    "                logging.warning(f'Waiting until {rate_limit_reset}')\n",
    "                delay_for_minutes(5)  # Reduced to 5 minutes\n",
    "            else:\n",
    "                logging.warning(f'Rate limit reset time is in the past. Waiting for 5 minutes as a precaution.')\n",
    "                delay_for_minutes(5)\n",
    "    except Exception as e:\n",
    "        logging.error(f'An error occurred: {e}')\n",
    "        if '403' in str(e):\n",
    "            logging.error('403 Forbidden error. Check your cookies and API permissions.')\n",
    "            switch_cookies()\n",
    "    return tweets\n",
    "\n",
    "def construct_query(date):\n",
    "    next_day = date + timedelta(days=1)\n",
    "    query = (f'(INFY OR Infosys OR \"Infosys Limited\" OR #INFY OR #Infosys OR '\n",
    "             f'Stock OR Market OR #StockMarket OR #MarketAnalysis) '\n",
    "             f'lang:en until:{next_day.strftime(\"%Y-%m-%d\")} since:{date.strftime(\"%Y-%m-%d\")}')\n",
    "    return query\n",
    "\n",
    "def delay_for_minutes(minutes=5):\n",
    "    \"\"\"Delays for the specified number of minutes, showing progress with tqdm.\"\"\"\n",
    "    wait_time = minutes * 60  # Convert minutes to seconds\n",
    "    with tqdm(total=wait_time, desc=f'Waiting for {minutes} minutes', unit='s', leave=True) as rate_pbar:\n",
    "        for _ in range(wait_time):\n",
    "            time.sleep(1)\n",
    "            rate_pbar.update(1)\n",
    "\n",
    "def collect_tweets_for_day(date):\n",
    "    global total_tweets_collected\n",
    "    query = construct_query(date)\n",
    "    tweet_count = 0\n",
    "    tweets = None\n",
    "    daily_tweet_data = []\n",
    "    \n",
    "    while tweet_count < MINIMUM_TWEETS:\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "        except TooManyRequests:\n",
    "            # Handle rate limit and cookie switch internally\n",
    "            continue\n",
    "\n",
    "        if not tweets:\n",
    "            logging.info(f'No more tweets found for {date.strftime(\"%Y-%m-%d\")}')\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if tweet_count >= MINIMUM_TWEETS:\n",
    "                break\n",
    "            tweet_count += 1\n",
    "            total_tweets_collected += 1\n",
    "            daily_tweet_data.append([date.strftime('%Y-%m-%d'), tweet_count, tweet.user.name, tweet.text, tweet.created_at, tweet.retweet_count, tweet.favorite_count])\n",
    "\n",
    "        logging.info(f'Got {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}')\n",
    "        daily_stats.append([date.strftime('%Y-%m-%d'), tweet_count])\n",
    "    \n",
    "    # Write daily tweet data to CSV after processing all tweets for the day\n",
    "    with open(CSV_FILE, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(daily_tweet_data)\n",
    "\n",
    "    if tweet_count < MINIMUM_TWEETS:\n",
    "        logging.warning(f'Collected {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}, which is less than the minimum of {MINIMUM_TWEETS}')\n",
    "    \n",
    "    logging.info(f'Done for {date.strftime(\"%Y-%m-%d\")}')\n",
    "    print(f'Total tweets collected so far: {total_tweets_collected}')\n",
    "\n",
    "def get_last_collected_date():\n",
    "    \"\"\"Reads the CSV file to find the last collected date.\"\"\"\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        return START_DATE\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        if len(rows) > 1:\n",
    "            last_date = rows[-1][0]\n",
    "            return datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    return START_DATE\n",
    "\n",
    "# Write header to the CSV file if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweet Count', 'Username', 'Text', 'Created At', 'Retweets', 'Likes'])\n",
    "\n",
    "# Get the starting date\n",
    "start_date = get_last_collected_date()\n",
    "if start_date > END_DATE:\n",
    "    print(f'All data has already been collected up to {END_DATE.strftime(\"%Y-%m-%d\")}.')\n",
    "else:\n",
    "    # Collect tweets for the specified date range\n",
    "    current_date = start_date\n",
    "    while current_date <= END_DATE:\n",
    "        collect_tweets_for_day(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    print(f'Finished collecting tweets. Total tweets collected: {total_tweets_collected}')\n",
    "\n",
    "    # Save summary to a CSV file\n",
    "    with open(SUMMARY_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweets Collected'])\n",
    "        writer.writerows(daily_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9eb7f-b67c-4d87-8d31-8641b65f8410",
   "metadata": {},
   "source": [
    "# ICICI Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f063232-132e-40e9-a6f6-770e37903f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Tweets: 100%|████████████████████████████████████████████████████████████| 730/730 [47:44<00:00,  3.92s/day]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished collecting tweets. Total tweets collected: 6640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MINIMUM_TWEETS = 10\n",
    "START_DATE = datetime(2022, 1, 1)  # Start date of the range\n",
    "END_DATE = datetime(2023, 12, 31)  # End date of the range\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Delay between requests in seconds\n",
    "CSV_FILE = 'ICICI.csv'  # Updated file for ICICI Bank data\n",
    "SUMMARY_FILE = 'ICICI_Collection_Summary.csv'  # Updated summary file for ICICI Bank\n",
    "\n",
    "# Initialize Twitter client\n",
    "client = Client()  # Initialize your Twitter client\n",
    "cookies_files = ['cookies.json', 'cookies2.json', 'cookies3.json', 'cookies4.json']\n",
    "current_cookie_index = 0\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='icici_tweet_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize counters\n",
    "total_tweets_collected = 0\n",
    "daily_stats = []\n",
    "\n",
    "def switch_cookies():\n",
    "    \"\"\"Switches between cookies.\"\"\"\n",
    "    global current_cookie_index\n",
    "    current_cookie_index = (current_cookie_index + 1) % len(cookies_files)\n",
    "    client.load_cookies(cookies_files[current_cookie_index])\n",
    "    logging.info(f'Switched to {cookies_files[current_cookie_index]}.')\n",
    "\n",
    "def get_tweets(query, tweets):\n",
    "    try:\n",
    "        if tweets is None:\n",
    "            logging.info(f'Getting tweets for query: {query}...')\n",
    "            tweets = client.search_tweet(query, product='Top')\n",
    "        else:\n",
    "            wait_time = randint(5, 10)\n",
    "            logging.info(f'Getting next tweets after {wait_time} seconds ...')\n",
    "            time.sleep(wait_time)\n",
    "            tweets = tweets.next()\n",
    "    except TooManyRequests as e:\n",
    "        rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "        current_time = datetime.now()\n",
    "        wait_time = (rate_limit_reset - current_time).total_seconds()\n",
    "        \n",
    "        logging.warning(f'Rate limit reached. Switching cookies.')\n",
    "        switch_cookies()  # Logging cookie switch\n",
    "\n",
    "        # Retry with new cookies\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "            logging.info('Successfully resumed after switching cookies.')\n",
    "        except TooManyRequests as e:\n",
    "            logging.warning(f'Rate limit still in place even after switching cookies.')\n",
    "            if wait_time > 0:\n",
    "                logging.warning(f'Waiting until {rate_limit_reset}')\n",
    "                delay_for_minutes(5)  # Reduced to 5 minutes\n",
    "            else:\n",
    "                logging.warning(f'Rate limit reset time is in the past. Waiting for 5 minutes as a precaution.')\n",
    "                delay_for_minutes(5)\n",
    "    except Exception as e:\n",
    "        logging.error(f'An error occurred: {e}')\n",
    "        if '403' in str(e):\n",
    "            logging.error('403 Forbidden error. Check your cookies and API permissions.')\n",
    "            switch_cookies()\n",
    "    return tweets\n",
    "\n",
    "def construct_query(date):\n",
    "    next_day = date + timedelta(days=1)\n",
    "    query = (f'(ICICI OR ICICIBank OR \"ICICI Bank\" OR #ICICIBank OR #ICICI OR '\n",
    "             f'Stock OR Market OR #StockMarket OR #MarketAnalysis) '\n",
    "             f'lang:en until:{next_day.strftime(\"%Y-%m-%d\")} since:{date.strftime(\"%Y-%m-%d\")}')\n",
    "    return query\n",
    "\n",
    "def delay_for_minutes(minutes=5):\n",
    "    \"\"\"Delays for the specified number of minutes, showing progress with tqdm.\"\"\"\n",
    "    wait_time = minutes * 60  # Convert minutes to seconds\n",
    "    with tqdm(total=wait_time, desc=f'Waiting for {minutes} minutes', unit='s', leave=True) as rate_pbar:\n",
    "        for _ in range(wait_time):\n",
    "            time.sleep(1)\n",
    "            rate_pbar.update(1)\n",
    "\n",
    "def collect_tweets_for_day(date):\n",
    "    global total_tweets_collected\n",
    "    query = construct_query(date)\n",
    "    tweet_count = 0\n",
    "    tweets = None\n",
    "    daily_tweet_data = []\n",
    "    \n",
    "    while tweet_count < MINIMUM_TWEETS:\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "        except TooManyRequests:\n",
    "            # Handle rate limit and cookie switch internally\n",
    "            continue\n",
    "\n",
    "        if not tweets:\n",
    "            logging.info(f'No more tweets found for {date.strftime(\"%Y-%m-%d\")}')\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if tweet_count >= MINIMUM_TWEETS:\n",
    "                break\n",
    "            tweet_count += 1\n",
    "            total_tweets_collected += 1\n",
    "            daily_tweet_data.append([date.strftime('%Y-%m-%d'), tweet_count, tweet.user.name, tweet.text, tweet.created_at, tweet.retweet_count, tweet.favorite_count])\n",
    "\n",
    "        logging.info(f'Got {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}')\n",
    "        daily_stats.append([date.strftime('%Y-%m-%d'), tweet_count])\n",
    "    \n",
    "    # Write daily tweet data to CSV after processing all tweets for the day\n",
    "    with open(CSV_FILE, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(daily_tweet_data)\n",
    "\n",
    "    if tweet_count < MINIMUM_TWEETS:\n",
    "        logging.warning(f'Collected {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}, which is less than the minimum of {MINIMUM_TWEETS}')\n",
    "    \n",
    "    logging.info(f'Done for {date.strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "\n",
    "def get_last_collected_date():\n",
    "    \"\"\"Reads the CSV file to find the last collected date.\"\"\"\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        return START_DATE\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        if len(rows) > 1:\n",
    "            last_date = rows[-1][0]\n",
    "            return datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    return START_DATE\n",
    "\n",
    "# Write header to the CSV file if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweet Count', 'Username', 'Text', 'Created At', 'Retweets', 'Likes'])\n",
    "\n",
    "# Get the starting date\n",
    "start_date = get_last_collected_date()\n",
    "\n",
    "# Calculate total number of days to collect tweets for progress bar\n",
    "total_days = (END_DATE - start_date).days + 1\n",
    "\n",
    "if start_date > END_DATE:\n",
    "    print(f'All data has already been collected up to {END_DATE.strftime(\"%Y-%m-%d\")}.')\n",
    "else:\n",
    "    # Collect tweets for the specified date range with progress bar\n",
    "    with tqdm(total=total_days, desc=\"Collecting Tweets\", unit=\"day\") as pbar:\n",
    "        current_date = start_date\n",
    "        while current_date <= END_DATE:\n",
    "            collect_tweets_for_day(current_date)\n",
    "            current_date += timedelta(days=1)\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f'Finished collecting tweets. Total tweets collected: {total_tweets_collected}')\n",
    "\n",
    "    # Save summary to a CSV file\n",
    "    with open(SUMMARY_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweets Collected'])\n",
    "        writer.writerows(daily_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0132ab-3400-4ff6-9ed2-f4a74eeae487",
   "metadata": {},
   "source": [
    "# HINDUNILVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105160f-c9da-4589-b86f-1e8fe50712a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MINIMUM_TWEETS = 10\n",
    "START_DATE = datetime(2022, 1, 1)  # Start date of the range\n",
    "END_DATE = datetime(2023, 12, 31)  # End date of the range\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Delay between requests in seconds\n",
    "CSV_FILE = 'HINDUNILVR.csv'  # File to store Hindustan Unilever tweets\n",
    "SUMMARY_FILE = 'HINDUNILVR_Collection_Summary.csv'  # File to store collection summary\n",
    "\n",
    "# Initialize Twitter client\n",
    "client = Client()  # Initialize your Twitter client\n",
    "client.load_cookies('cookies.json')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='tweet_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize counters\n",
    "total_tweets_collected = 0\n",
    "daily_stats = []\n",
    "\n",
    "def get_tweets(query, tweets):\n",
    "    if tweets is None:\n",
    "        logging.info(f'Getting tweets for query: {query}...')\n",
    "        tweets = client.search_tweet(query, product='Top')\n",
    "    else:\n",
    "        wait_time = randint(5, 10)\n",
    "        logging.info(f'Getting next tweets after {wait_time} seconds ...')\n",
    "        time.sleep(wait_time)\n",
    "        tweets = tweets.next()\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def construct_query(date):\n",
    "    next_day = date + timedelta(days=1)\n",
    "    query = (f'(HUL OR HINDUNILVR OR \"Hindustan Unilever\" OR #HUL OR #HINDUNILVR OR '\n",
    "             f'Stock OR Market OR #StockMarket OR #MarketAnalysis) '\n",
    "             f'lang:en until:{next_day.strftime(\"%Y-%m-%d\")} since:{date.strftime(\"%Y-%m-%d\")}')\n",
    "    return query\n",
    "\n",
    "def delay_for_minutes(minutes=15):\n",
    "    \"\"\"Delays for the specified number of minutes, showing progress with tqdm.\"\"\"\n",
    "    wait_time = minutes * 60  # Convert minutes to seconds\n",
    "    with tqdm(total=wait_time, desc=f'Waiting for {minutes} minutes', unit='s', leave=True) as rate_pbar:\n",
    "        for _ in range(wait_time):\n",
    "            time.sleep(1)\n",
    "            rate_pbar.update(1)\n",
    "\n",
    "def collect_tweets_for_day(date):\n",
    "    global total_tweets_collected\n",
    "    query = construct_query(date)\n",
    "    tweet_count = 0\n",
    "    tweets = None\n",
    "    \n",
    "    while tweet_count < MINIMUM_TWEETS:\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "        except TooManyRequests as e:\n",
    "            rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "            current_time = datetime.now()\n",
    "            wait_time = (rate_limit_reset - current_time).total_seconds()\n",
    "            if wait_time > 0:\n",
    "                logging.warning(f'Rate limit reached. Waiting until {rate_limit_reset}')\n",
    "                delay_for_minutes(wait_time // 60)  # Convert wait_time to minutes for tqdm\n",
    "            else:\n",
    "                logging.warning(f'Rate limit reset time is in the past. Continuing immediately.')\n",
    "                delay_for_minutes(15)  # 15-minute delay in case of past reset time\n",
    "            continue\n",
    "\n",
    "        if not tweets:\n",
    "            logging.info(f'No more tweets found for {date.strftime(\"%Y-%m-%d\")}')\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if tweet_count >= MINIMUM_TWEETS:\n",
    "                break\n",
    "            tweet_count += 1\n",
    "            total_tweets_collected += 1\n",
    "            tweet_data = [date.strftime('%Y-%m-%d'), tweet_count, tweet.user.name, tweet.text, tweet.created_at, tweet.retweet_count, tweet.favorite_count]\n",
    "            \n",
    "            with open(CSV_FILE, 'a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(tweet_data)\n",
    "\n",
    "        logging.info(f'Got {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}')\n",
    "        daily_stats.append([date.strftime('%Y-%m-%d'), tweet_count])\n",
    "    \n",
    "    if tweet_count < MINIMUM_TWEETS:\n",
    "        logging.warning(f'Collected {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}, which is less than the minimum of {MINIMUM_TWEETS}')\n",
    "    \n",
    "    logging.info(f'Done for {date.strftime(\"%Y-%m-%d\")}')\n",
    "    print(f'Total tweets collected so far: {total_tweets_collected}')\n",
    "\n",
    "def get_last_collected_date():\n",
    "    \"\"\"Reads the CSV file to find the last collected date.\"\"\"\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        return START_DATE\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        if len(rows) > 1:\n",
    "            last_date = rows[-1][0]\n",
    "            return datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    return START_DATE\n",
    "\n",
    "# Write header to the CSV file if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweet Count', 'Username', 'Text', 'Created At', 'Retweets', 'Likes'])\n",
    "\n",
    "# Get the starting date\n",
    "start_date = get_last_collected_date()\n",
    "if start_date > END_DATE:\n",
    "    print(f'All data has already been collected up to {END_DATE.strftime(\"%Y-%m-%d\")}.')\n",
    "else:\n",
    "    # Collect tweets for the specified date range\n",
    "    current_date = start_date\n",
    "    while current_date <= END_DATE:\n",
    "        collect_tweets_for_day(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    print(f'Finished collecting tweets. Total tweets collected: {total_tweets_collected}')\n",
    "\n",
    "    # Save summary to a CSV file\n",
    "    with open(SUMMARY_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweets Collected'])\n",
    "        writer.writerows(daily_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7d05c-b6ad-4e0f-b781-15b82c2cd19d",
   "metadata": {},
   "source": [
    "# ITC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525bef8-b595-4e3a-af7d-8f4e57a52e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MINIMUM_TWEETS = 10\n",
    "START_DATE = datetime(2022, 1, 1)  # Start date of the range\n",
    "END_DATE = datetime(2023, 12, 31)  # End date of the range\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Delay between requests in seconds\n",
    "CSV_FILE = 'ITC.csv'  # File to store ITC tweets\n",
    "SUMMARY_FILE = 'ITC_Collection_Summary.csv'  # File to store collection summary\n",
    "\n",
    "# Initialize Twitter client\n",
    "client = Client()  # Initialize your Twitter client\n",
    "client.load_cookies('cookies.json')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='tweet_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize counters\n",
    "total_tweets_collected = 0\n",
    "daily_stats = []\n",
    "\n",
    "def get_tweets(query, tweets):\n",
    "    if tweets is None:\n",
    "        logging.info(f'Getting tweets for query: {query}...')\n",
    "        tweets = client.search_tweet(query, product='Top')\n",
    "    else:\n",
    "        wait_time = randint(5, 10)\n",
    "        logging.info(f'Getting next tweets after {wait_time} seconds ...')\n",
    "        time.sleep(wait_time)\n",
    "        tweets = tweets.next()\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def construct_query(date):\n",
    "    next_day = date + timedelta(days=1)\n",
    "    query = (f'(ITC OR #ITC OR \"ITC Ltd\" OR #ITCLimited OR '\n",
    "             f'Stock OR Market OR #StockMarket OR #MarketAnalysis) '\n",
    "             f'lang:en until:{next_day.strftime(\"%Y-%m-%d\")} since:{date.strftime(\"%Y-%m-%d\")}')\n",
    "    return query\n",
    "\n",
    "def delay_for_minutes(minutes=15):\n",
    "    \"\"\"Delays for the specified number of minutes, showing progress with tqdm.\"\"\"\n",
    "    wait_time = minutes * 60  # Convert minutes to seconds\n",
    "    with tqdm(total=wait_time, desc=f'Waiting for {minutes} minutes', unit='s', leave=True) as rate_pbar:\n",
    "        for _ in range(wait_time):\n",
    "            time.sleep(1)\n",
    "            rate_pbar.update(1)\n",
    "\n",
    "def collect_tweets_for_day(date):\n",
    "    global total_tweets_collected\n",
    "    query = construct_query(date)\n",
    "    tweet_count = 0\n",
    "    tweets = None\n",
    "    \n",
    "    while tweet_count < MINIMUM_TWEETS:\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "        except TooManyRequests as e:\n",
    "            rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "            current_time = datetime.now()\n",
    "            wait_time = (rate_limit_reset - current_time).total_seconds()\n",
    "            if wait_time > 0:\n",
    "                logging.warning(f'Rate limit reached. Waiting until {rate_limit_reset}')\n",
    "                delay_for_minutes(wait_time // 60)  # Convert wait_time to minutes for tqdm\n",
    "            else:\n",
    "                logging.warning(f'Rate limit reset time is in the past. Continuing immediately.')\n",
    "                delay_for_minutes(15)  # 15-minute delay in case of past reset time\n",
    "            continue\n",
    "\n",
    "        if not tweets:\n",
    "            logging.info(f'No more tweets found for {date.strftime(\"%Y-%m-%d\")}')\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if tweet_count >= MINIMUM_TWEETS:\n",
    "                break\n",
    "            tweet_count += 1\n",
    "            total_tweets_collected += 1\n",
    "            tweet_data = [date.strftime('%Y-%m-%d'), tweet_count, tweet.user.name, tweet.text, tweet.created_at, tweet.retweet_count, tweet.favorite_count]\n",
    "            \n",
    "            with open(CSV_FILE, 'a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(tweet_data)\n",
    "\n",
    "        logging.info(f'Got {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}')\n",
    "        daily_stats.append([date.strftime('%Y-%m-%d'), tweet_count])\n",
    "    \n",
    "    if tweet_count < MINIMUM_TWEETS:\n",
    "        logging.warning(f'Collected {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}, which is less than the minimum of {MINIMUM_TWEETS}')\n",
    "    \n",
    "    logging.info(f'Done for {date.strftime(\"%Y-%m-%d\")}')\n",
    "    print(f'Total tweets collected so far: {total_tweets_collected}')\n",
    "\n",
    "def get_last_collected_date():\n",
    "    \"\"\"Reads the CSV file to find the last collected date.\"\"\"\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        return START_DATE\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        if len(rows) > 1:\n",
    "            last_date = rows[-1][0]\n",
    "            return datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    return START_DATE\n",
    "\n",
    "# Write header to the CSV file if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweet Count', 'Username', 'Text', 'Created At', 'Retweets', 'Likes'])\n",
    "\n",
    "# Get the starting date\n",
    "start_date = get_last_collected_date()\n",
    "if start_date > END_DATE:\n",
    "    print(f'All data has already been collected up to {END_DATE.strftime(\"%Y-%m-%d\")}.')\n",
    "else:\n",
    "    # Collect tweets for the specified date range\n",
    "    current_date = start_date\n",
    "    while current_date <= END_DATE:\n",
    "        collect_tweets_for_day(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    print(f'Finished collecting tweets. Total tweets collected: {total_tweets_collected}')\n",
    "\n",
    "    # Save summary to a CSV file\n",
    "    with open(SUMMARY_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweets Collected'])\n",
    "        writer.writerows(daily_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebaba4c-c2c2-486e-a2b7-fdea282aec34",
   "metadata": {},
   "source": [
    "# SBIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a75b6-6360-4589-9a65-b40ef3ac5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "from twikit import Client, TooManyRequests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MINIMUM_TWEETS = 10\n",
    "START_DATE = datetime(2022, 1, 1)  # Start date of the range\n",
    "END_DATE = datetime(2023, 12, 31)  # End date of the range\n",
    "DELAY_BETWEEN_REQUESTS = 1  # Delay between requests in seconds\n",
    "CSV_FILE = 'SBIN.csv'  # File to store SBIN tweets\n",
    "SUMMARY_FILE = 'SBIN_Collection_Summary.csv'  # File to store collection summary\n",
    "\n",
    "# Initialize Twitter client\n",
    "client = Client()  # Initialize your Twitter client\n",
    "client.load_cookies('cookies.json')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='tweet_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize counters\n",
    "total_tweets_collected = 0\n",
    "daily_stats = []\n",
    "\n",
    "def get_tweets(query, tweets):\n",
    "    if tweets is None:\n",
    "        logging.info(f'Getting tweets for query: {query}...')\n",
    "        tweets = client.search_tweet(query, product='Top')\n",
    "    else:\n",
    "        wait_time = randint(5, 10)\n",
    "        logging.info(f'Getting next tweets after {wait_time} seconds ...')\n",
    "        time.sleep(wait_time)\n",
    "        tweets = tweets.next()\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def construct_query(date):\n",
    "    next_day = date + timedelta(days=1)\n",
    "    query = (f'(SBIN OR \"State Bank of India\" OR #SBI OR #SBIN OR \"SBI Bank\" OR '\n",
    "             f'Stock OR Market OR #StockMarket OR #MarketAnalysis) '\n",
    "             f'lang:en until:{next_day.strftime(\"%Y-%m-%d\")} since:{date.strftime(\"%Y-%m-%d\")}')\n",
    "    return query\n",
    "\n",
    "def delay_for_minutes(minutes=15):\n",
    "    \"\"\"Delays for the specified number of minutes, showing progress with tqdm.\"\"\"\n",
    "    wait_time = minutes * 60  # Convert minutes to seconds\n",
    "    with tqdm(total=wait_time, desc=f'Waiting for {minutes} minutes', unit='s', leave=True) as rate_pbar:\n",
    "        for _ in range(wait_time):\n",
    "            time.sleep(1)\n",
    "            rate_pbar.update(1)\n",
    "\n",
    "def collect_tweets_for_day(date):\n",
    "    global total_tweets_collected\n",
    "    query = construct_query(date)\n",
    "    tweet_count = 0\n",
    "    tweets = None\n",
    "    \n",
    "    while tweet_count < MINIMUM_TWEETS:\n",
    "        try:\n",
    "            tweets = get_tweets(query, tweets)\n",
    "        except TooManyRequests as e:\n",
    "            rate_limit_reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "            current_time = datetime.now()\n",
    "            wait_time = (rate_limit_reset - current_time).total_seconds()\n",
    "            if wait_time > 0:\n",
    "                logging.warning(f'Rate limit reached. Waiting until {rate_limit_reset}')\n",
    "                delay_for_minutes(wait_time // 60)  # Convert wait_time to minutes for tqdm\n",
    "            else:\n",
    "                logging.warning(f'Rate limit reset time is in the past. Continuing immediately.')\n",
    "                delay_for_minutes(15)  # 15-minute delay in case of past reset time\n",
    "            continue\n",
    "\n",
    "        if not tweets:\n",
    "            logging.info(f'No more tweets found for {date.strftime(\"%Y-%m-%d\")}')\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if tweet_count >= MINIMUM_TWEETS:\n",
    "                break\n",
    "            tweet_count += 1\n",
    "            total_tweets_collected += 1\n",
    "            tweet_data = [date.strftime('%Y-%m-%d'), tweet_count, tweet.user.name, tweet.text, tweet.created_at, tweet.retweet_count, tweet.favorite_count]\n",
    "            \n",
    "            with open(CSV_FILE, 'a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(tweet_data)\n",
    "\n",
    "        logging.info(f'Got {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}')\n",
    "        daily_stats.append([date.strftime('%Y-%m-%d'), tweet_count])\n",
    "    \n",
    "    if tweet_count < MINIMUM_TWEETS:\n",
    "        logging.warning(f'Collected {tweet_count} tweets for {date.strftime(\"%Y-%m-%d\")}, which is less than the minimum of {MINIMUM_TWEETS}')\n",
    "    \n",
    "    logging.info(f'Done for {date.strftime(\"%Y-%m-%d\")}')\n",
    "    print(f'Total tweets collected so far: {total_tweets_collected}')\n",
    "\n",
    "def get_last_collected_date():\n",
    "    \"\"\"Reads the CSV file to find the last collected date.\"\"\"\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        return START_DATE\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        if len(rows) > 1:\n",
    "            last_date = rows[-1][0]\n",
    "            return datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    return START_DATE\n",
    "\n",
    "# Write header to the CSV file if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweet Count', 'Username', 'Text', 'Created At', 'Retweets', 'Likes'])\n",
    "\n",
    "# Get the starting date\n",
    "start_date = get_last_collected_date()\n",
    "if start_date > END_DATE:\n",
    "    print(f'All data has already been collected up to {END_DATE.strftime(\"%Y-%m-%d\")}.')\n",
    "else:\n",
    "    # Collect tweets for the specified date range\n",
    "    current_date = start_date\n",
    "    while current_date <= END_DATE:\n",
    "        collect_tweets_for_day(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    print(f'Finished collecting tweets. Total tweets collected: {total_tweets_collected}')\n",
    "\n",
    "    # Save summary to a CSV file\n",
    "    with open(SUMMARY_FILE, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date', 'Tweets Collected'])\n",
    "        writer.writerows(daily_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27ab91-3c70-4e0f-a47b-58c215437946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
